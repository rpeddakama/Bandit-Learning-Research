# Bandit Learning Research

Multi-armed bandit algorithms; Research done at Dr Ji's [SNAIL](https://people.cs.vt.edu/boji/group.html) lab @ Virginia Tech
Implements different bandit algorithms that solve the exploration vs exploitation problem.

## Algorithms

- **Epsilon-greedy**: Random exploration with probability Îµ
- **UCB**: Upper confidence bound approach  
- **Thompson Sampling**: Bayesian method
- **Contextual bandits**: Uses additional info to make decisions

## Requirements

numpy, matplotlib, scipy
